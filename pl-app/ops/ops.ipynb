{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd3be722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b88fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_to(base, x, y):\n",
    "    np_input = x.detach().numpy()\n",
    "    with open(os.path.join(base, 'dummy_in.dat'), 'wb') as f:\n",
    "        np_input.tofile(f)\n",
    "\n",
    "    np_output = y.detach().numpy()\n",
    "    with open(os.path.join(base, 'dummy_out.dat'), 'wb') as f:\n",
    "        np_output.tofile(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7df37394",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=0, bias=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9dc66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(10000, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba0f851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 752 ms, sys: 1.5 s, total: 2.26 s\n",
      "Wall time: 204 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y = conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "488506c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = [\"image\"]\n",
    "output_names = [\"prediction\"]\n",
    "dummy_input = torch.randn(10000, 1, 28, 28)\n",
    "torch.onnx.export(conv,\n",
    "                  dummy_input,\n",
    "                  \"conv/convolution1.onnx\",\n",
    "                  verbose=False,\n",
    "                  input_names=input_names,\n",
    "                  output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5705d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = nn.Conv2d(64, 64, kernel_size=1, stride=1, padding=0, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b08bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(128, 64, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e339ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.43 s, sys: 1.82 s, total: 4.25 s\n",
      "Wall time: 4.25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y = conv2(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "600a0667",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = [\"image\"]\n",
    "output_names = [\"prediction\"]\n",
    "dummy_input = torch.randn(128, 64, 224, 224)\n",
    "torch.onnx.export(conv2,\n",
    "                  dummy_input,\n",
    "                  \"conv/conv_opt.onnx\",\n",
    "                  verbose=False,\n",
    "                  input_names=input_names,\n",
    "                  output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ced4bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b324c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 508 ms, sys: 1.62 s, total: 2.13 s\n",
      "Wall time: 136 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 64, 24, 24])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y = r2(y)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35011157",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = [\"image\"]\n",
    "output_names = [\"prediction\"]\n",
    "dummy_input = torch.randn(10000, 64, 24, 24)\n",
    "torch.onnx.export(r2,\n",
    "                  dummy_input,\n",
    "                  \"relu/r2.onnx\",\n",
    "                  verbose=False,\n",
    "                  input_names=input_names,\n",
    "                  output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48b4cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = nn.MaxPool2d(kernel_size=2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1459e19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.6 s, sys: 500 ms, total: 3.1 s\n",
      "Wall time: 229 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 64, 12, 12])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y = mp(y)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fc607d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = [\"image\"]\n",
    "output_names = [\"prediction\"]\n",
    "dummy_input = torch.randn(10000, 64, 24, 24)\n",
    "torch.onnx.export(mp,\n",
    "                  dummy_input,\n",
    "                  \"maxpool/maxpool.onnx\",\n",
    "                  verbose=False,\n",
    "                  input_names=input_names,\n",
    "                  output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a47c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.LogSoftmax(dim=1)\n",
    "x = torch.rand(10000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48d9ff04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 80 ms, sys: 200 ms, total: 280 ms\n",
      "Wall time: 208 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y = softmax(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96e3dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = [\"image\"]\n",
    "output_names = [\"prediction\"]\n",
    "dummy_input = torch.randn(10000, 10)\n",
    "torch.onnx.export(softmax,\n",
    "                  dummy_input,\n",
    "                  \"Lsm/lsm.onnx\",\n",
    "                  verbose=False,\n",
    "                  input_names=input_names,\n",
    "                  output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05cd6eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerEncoderLayer(\n",
      "  (self_attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout1): Dropout(p=0.1, inplace=False)\n",
      "  (dropout2): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=2, batch_first=False)\n",
    "x = torch.rand(7 * 24 * 6, 64, 512)\n",
    "print(encoder_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dc3ede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 2.89 s, total: 17.4 s\n",
      "Wall time: 17.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1008, 64, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y = encoder_layer(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f07147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to('attention', x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede4ee3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%series : Float(1008, 64, 512, strides=[32768, 512, 1], requires_grad=0, device=cpu),\n",
      "      %self_attn.in_proj_bias : Float(1536, strides=[1], requires_grad=1, device=cpu),\n",
      "      %self_attn.out_proj.weight : Float(512, 512, strides=[512, 1], requires_grad=1, device=cpu),\n",
      "      %self_attn.out_proj.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %linear1.bias : Float(2048, strides=[1], requires_grad=1, device=cpu),\n",
      "      %linear2.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %norm1.weight : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::MatMul_121 : Float(512, 1536, strides=[1, 512], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_141 : Float(512, 2048, strides=[1, 512], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_142 : Float(2048, 512, strides=[1, 2048], requires_grad=0, device=cpu)):\n",
      "  %norm2.bias : Float(512, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%self_attn.out_proj.bias)\n",
      "  %norm2.weight : Float(512, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%norm1.weight)\n",
      "  %norm1.bias : Float(512, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%self_attn.out_proj.bias)\n",
      "  %/self_attn/MatMul_output_0 : Float(1008, 64, 1536, strides=[98304, 1536, 1], device=cpu) = onnx::MatMul[onnx_name=\"/self_attn/MatMul\"](%series, %onnx::MatMul_121), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Add_output_0 : Float(1008, 64, 1536, strides=[98304, 1536, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/self_attn/Add\"](%self_attn.in_proj_bias, %/self_attn/MatMul_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/self_attn/Shape\"](%/self_attn/Add_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/self_attn/Constant\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Gather_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/self_attn/Gather\"](%/self_attn/Shape_output_0, %/self_attn/Constant_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/self_attn/Constant_1\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/self_attn/Constant_2\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Add_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name=\"/self_attn/Add_1\"](%/self_attn/Gather_output_0, %/self_attn/Constant_2_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/self_attn/Constant_3\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Div_output_0 : Long(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/self_attn/Div\"](%/self_attn/Add_1_output_0, %/self_attn/Constant_3_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/self_attn/Constant_4\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Mul_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/self_attn/Mul\"](%/self_attn/Div_output_0, %/self_attn/Constant_4_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Slice_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/self_attn/Slice\"](%/self_attn/Add_output_0, %/self_attn/Constant_1_output_0, %/self_attn/Mul_output_0, %/self_attn/Constant_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/self_attn/Constant_5\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Mul_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/self_attn/Mul_1\"](%/self_attn/Div_output_0, %/self_attn/Constant_5_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Slice_1_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/self_attn/Slice_1\"](%/self_attn/Add_output_0, %/self_attn/Mul_output_0, %/self_attn/Mul_1_output_0, %/self_attn/Constant_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/self_attn/Constant_6\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Mul_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/self_attn/Mul_2\"](%/self_attn/Div_output_0, %/self_attn/Constant_6_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Slice_2_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], requires_grad=1, device=cpu) = onnx::Slice[onnx_name=\"/self_attn/Slice_2\"](%/self_attn/Add_output_0, %/self_attn/Mul_1_output_0, %/self_attn/Mul_2_output_0, %/self_attn/Constant_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:4737:0\n",
      "  %/self_attn/Constant_7_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1008   128   256 [ CPULongType{3} ], onnx_name=\"/self_attn/Constant_7\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5095:0\n",
      "  %/self_attn/Reshape_output_0 : Float(1008, 128, 256, strides=[32768, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/self_attn/Reshape\"](%/self_attn/Slice_output_0, %/self_attn/Constant_7_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5095:0\n",
      "  %/self_attn/Transpose_output_0 : Float(128, 1008, 256, strides=[256, 32768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/self_attn/Transpose\"](%/self_attn/Reshape_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5095:0\n",
      "  %/self_attn/Constant_8_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1008   128   256 [ CPULongType{3} ], onnx_name=\"/self_attn/Constant_8\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5097:0\n",
      "  %/self_attn/Reshape_1_output_0 : Float(1008, 128, 256, strides=[32768, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/self_attn/Reshape_1\"](%/self_attn/Slice_1_output_0, %/self_attn/Constant_8_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5097:0\n",
      "  %/self_attn/Constant_9_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1008   128   256 [ CPULongType{3} ], onnx_name=\"/self_attn/Constant_9\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5106:0\n",
      "  %/self_attn/Reshape_2_output_0 : Float(1008, 128, 256, strides=[32768, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/self_attn/Reshape_2\"](%/self_attn/Slice_2_output_0, %/self_attn/Constant_9_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5106:0\n",
      "  %/self_attn/Transpose_1_output_0 : Float(128, 1008, 256, strides=[256, 32768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/self_attn/Transpose_1\"](%/self_attn/Reshape_2_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5106:0\n",
      "  %/self_attn/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/self_attn/Constant_10\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5156:0\n",
      "  %/self_attn/Div_1_output_0 : Float(128, 1008, 256, strides=[256, 32768, 1], requires_grad=1, device=cpu) = onnx::Div[onnx_name=\"/self_attn/Div_1\"](%/self_attn/Transpose_output_0, %/self_attn/Constant_10_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5156:0\n",
      "  %/self_attn/Transpose_2_output_0 : Float(128, 256, 1008, strides=[256, 1, 32768], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 2, 0], onnx_name=\"/self_attn/Transpose_2\"](%/self_attn/Reshape_1_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5160:0\n",
      "  %/self_attn/MatMul_1_output_0 : Float(128, 1008, 1008, strides=[1016064, 1008, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/self_attn/MatMul_1\"](%/self_attn/Div_1_output_0, %/self_attn/Transpose_2_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5160:0\n",
      "  %/self_attn/Softmax_output_0 : Float(128, 1008, 1008, strides=[1016064, 1008, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/self_attn/Softmax\"](%/self_attn/MatMul_1_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:1841:0\n",
      "  %/self_attn/MatMul_2_output_0 : Float(128, 1008, 256, strides=[258048, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul[onnx_name=\"/self_attn/MatMul_2\"](%/self_attn/Softmax_output_0, %/self_attn/Transpose_1_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5165:0\n",
      "  %/self_attn/Transpose_3_output_0 : Float(1008, 128, 256, strides=[32768, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/self_attn/Transpose_3\"](%/self_attn/MatMul_2_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5167:0\n",
      "  %/self_attn/Constant_11_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 64512    512 [ CPULongType{2} ], onnx_name=\"/self_attn/Constant_11\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5167:0\n",
      "  %/self_attn/Reshape_3_output_0 : Float(64512, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/self_attn/Reshape_3\"](%/self_attn/Transpose_3_output_0, %/self_attn/Constant_11_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5167:0\n",
      "  %/self_attn/Gemm_output_0 : Float(64512, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/self_attn/Gemm\"](%/self_attn/Reshape_3_output_0, %self_attn.out_proj.weight, %self_attn.out_proj.bias), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5168:0\n",
      "  %/self_attn/Constant_12_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1008    64   512 [ CPULongType{3} ], onnx_name=\"/self_attn/Constant_12\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5169:0\n",
      "  %/self_attn/Reshape_4_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], requires_grad=1, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/self_attn/Reshape_4\"](%/self_attn/Gemm_output_0, %/self_attn/Constant_12_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.activation.MultiheadAttention::self_attn # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:5169:0\n",
      "  %/Add_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add\"](%series, %/self_attn/Reshape_4_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer:: # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/modules/transformer.py:538:0\n",
      "  %/norm1/ReduceMean_output_0 : Float(1008, 64, 1, strides=[64, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/norm1/ReduceMean\"](%/Add_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm1 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm1/Sub_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], device=cpu) = onnx::Sub[onnx_name=\"/norm1/Sub\"](%/Add_output_0, %/norm1/ReduceMean_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm1 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/norm1/Constant\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm1 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm1/Pow_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], device=cpu) = onnx::Pow[onnx_name=\"/norm1/Pow\"](%/norm1/Sub_output_0, %/norm1/Constant_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm1 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm1/ReduceMean_1_output_0 : Float(1008, 64, 1, strides=[64, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/norm1/ReduceMean_1\"](%/norm1/Pow_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm1 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name=\"/norm1/Constant_1\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm1 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm1/Add_output_0 : Float(1008, 64, 1, strides=[64, 1, 1], device=cpu) = onnx::Add[onnx_name=\"/norm1/Add\"](%/norm1/ReduceMean_1_output_0, %/norm1/Constant_1_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm1 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm1/Sqrt_output_0 : Float(1008, 64, 1, strides=[64, 1, 1], device=cpu) = onnx::Sqrt[onnx_name=\"/norm1/Sqrt\"](%/norm1/Add_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm1 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm1/Div_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], device=cpu) = onnx::Div[onnx_name=\"/norm1/Div\"](%/norm1/Sub_output_0, %/norm1/Sqrt_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm1 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm1/Mul_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], device=cpu) = onnx::Mul[onnx_name=\"/norm1/Mul\"](%/norm1/Div_output_0, %norm1.weight), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm1 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm1/Add_1_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/norm1/Add_1\"](%/norm1/Mul_output_0, %norm1.bias), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm1 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/linear1/MatMul_output_0 : Float(1008, 64, 2048, strides=[131072, 2048, 1], device=cpu) = onnx::MatMul[onnx_name=\"/linear1/MatMul\"](%/norm1/Add_1_output_0, %onnx::MatMul_141), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.linear.Linear::linear1 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/linear1/Add_output_0 : Float(1008, 64, 2048, strides=[131072, 2048, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/linear1/Add\"](%linear1.bias, %/linear1/MatMul_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.linear.Linear::linear1 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Relu_output_0 : Float(1008, 64, 2048, strides=[131072, 2048, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/Relu\"](%/linear1/Add_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer:: # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:1457:0\n",
      "  %/linear2/MatMul_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], device=cpu) = onnx::MatMul[onnx_name=\"/linear2/MatMul\"](%/Relu_output_0, %onnx::MatMul_142), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.linear.Linear::linear2 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/linear2/Add_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/linear2/Add\"](%linear2.bias, %/linear2/MatMul_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.linear.Linear::linear2 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Add_1_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_1\"](%/norm1/Add_1_output_0, %/linear2/Add_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer:: # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/modules/transformer.py:539:0\n",
      "  %/norm2/ReduceMean_output_0 : Float(1008, 64, 1, strides=[64, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/norm2/ReduceMean\"](%/Add_1_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm2 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm2/Sub_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], device=cpu) = onnx::Sub[onnx_name=\"/norm2/Sub\"](%/Add_1_output_0, %/norm2/ReduceMean_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm2 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/norm2/Constant\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm2 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm2/Pow_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], device=cpu) = onnx::Pow[onnx_name=\"/norm2/Pow\"](%/norm2/Sub_output_0, %/norm2/Constant_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm2 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm2/ReduceMean_1_output_0 : Float(1008, 64, 1, strides=[64, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/norm2/ReduceMean_1\"](%/norm2/Pow_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm2 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name=\"/norm2/Constant_1\"](), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm2 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm2/Add_output_0 : Float(1008, 64, 1, strides=[64, 1, 1], device=cpu) = onnx::Add[onnx_name=\"/norm2/Add\"](%/norm2/ReduceMean_1_output_0, %/norm2/Constant_1_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm2 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm2/Sqrt_output_0 : Float(1008, 64, 1, strides=[64, 1, 1], device=cpu) = onnx::Sqrt[onnx_name=\"/norm2/Sqrt\"](%/norm2/Add_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm2 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm2/Div_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], device=cpu) = onnx::Div[onnx_name=\"/norm2/Div\"](%/norm2/Sub_output_0, %/norm2/Sqrt_output_0), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm2 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %/norm2/Mul_output_0 : Float(1008, 64, 512, strides=[32768, 512, 1], device=cpu) = onnx::Mul[onnx_name=\"/norm2/Mul\"](%/norm2/Div_output_0, %norm2.weight), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm2 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  %prediction : Float(1008, 64, 512, strides=[32768, 512, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/norm2/Add_1\"](%/norm2/Mul_output_0, %norm2.bias), scope: torch.nn.modules.transformer.TransformerEncoderLayer::/torch.nn.modules.normalization.LayerNorm::norm2 # /users/Zijian/.local/lib/python3.8/site-packages/torch/nn/functional.py:2515:0\n",
      "  return (%prediction)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_names = [\"series\"]\n",
    "output_names = [\"prediction\"]\n",
    "dummy_input = x\n",
    "torch.onnx.export(encoder_layer,\n",
    "                  dummy_input,\n",
    "                  \"attention/encoder.onnx\",\n",
    "                  verbose=True,\n",
    "                  input_names=input_names,\n",
    "                  output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67af8b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerDecoderLayer(\n",
      "  (self_attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (multihead_attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout1): Dropout(p=0.1, inplace=False)\n",
      "  (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  (dropout3): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "decoder_layer = nn.TransformerDecoderLayer(d_model=768, nhead=8, dim_feedforward=3072)\n",
    "print(decoder_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba2d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
