{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dccfee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GenerationConfig, AutoTokenizer, GPT2Config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import transformers\n",
    "from onnxruntime import InferenceSession\n",
    "from transformers.onnx.features import FeaturesManager\n",
    "from optimum.exporters.tasks import TasksManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b49e7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_to(x, fp):\n",
    "    print(x.dtype)\n",
    "    np_x = x.detach().numpy()\n",
    "    with open(fp, 'wb') as f:\n",
    "        np_x.tofile(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae44fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2333)\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6934b327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['default',\n",
       " 'default-with-past',\n",
       " 'causal-lm',\n",
       " 'causal-lm-with-past',\n",
       " 'sequence-classification',\n",
       " 'token-classification']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_features = list(FeaturesManager.get_supported_features_for_model_type(\"gpt2\").keys())\n",
    "gpt2_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6133c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['default',\n",
       " 'default-with-past',\n",
       " 'causal-lm',\n",
       " 'causal-lm-with-past',\n",
       " 'sequence-classification',\n",
       " 'token-classification']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_tasks = list(TasksManager.get_supported_tasks_for_model_type(\"gpt2\", \"onnx\").keys())\n",
    "gpt2_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ab857",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('model_onnx')\n",
    "session = InferenceSession(\"model_onnx/model.onnx\")\n",
    "config = GPT2Config()\n",
    "onnx_config = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daa8700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.config.return_dict = False\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01eb94cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kind, model_onnx_config = FeaturesManager.check_supported_model_or_raise(model, feature='default-with-past')\n",
    "onnx_config = model_onnx_config(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9ff1cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/Zijian/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:794: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if batch_size <= 0:\n"
     ]
    }
   ],
   "source": [
    "onnx_inputs, onnx_outputs = transformers.onnx.export(\n",
    "    preprocessor=tokenizer,\n",
    "    model=model,\n",
    "    config=onnx_config,\n",
    "    opset=13,\n",
    "    output=Path(\"gpt2_model.onnx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb0cb00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'past_key_values', 'attention_mask']\n",
      "['last_hidden_state', 'present.0.key', 'present.0.value', 'present.1.key', 'present.1.value', 'present.2.key', 'present.2.value', 'present.3.key', 'present.3.value', 'present.4.key', 'present.4.value', 'present.5.key', 'present.5.value', 'present.6.key', 'present.6.value', 'present.7.key', 'present.7.value', 'present.8.key', 'present.8.value', 'present.9.key', 'present.9.value', 'present.10.key', 'present.10.value', 'present.11.key', 'present.11.value']\n"
     ]
    }
   ],
   "source": [
    "print(onnx_inputs)\n",
    "print(onnx_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eada2747",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cfg = GenerationConfig(\n",
    "    pad_token_id = tokenizer.eos_token_id, \n",
    "    use_cache = True,\n",
    "    max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afd62256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace me by any text you'd like.\n",
      "\n",
      "I'm not sure if you're aware of this, but I'm not sure if you're aware of this, but I'm not sure if you're aware of this, but I'm not sure if you're aware of this, but I'm not sure if you're aware of this, but I'm not sure if you're aware of this, but I'm not sure if you're aware of this, but I'm not sure if you're aware of this, but I'm not sure if you're aware of this, but I'm not sure if you're aware of this, but I'm not sure if you\n",
      "CPU times: user 5.14 s, sys: 264 ms, total: 5.41 s\n",
      "Wall time: 5.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output = model.generate(**encoded_input, generation_config=gen_cfg)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b0fd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11afa75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f94a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = [\"text\"]\n",
    "output_names = [\"prediction\"]\n",
    "dummy_input = torch.randint(0, 30522, (64, 20))\n",
    "\n",
    "torch.onnx.export(bert,\n",
    "                  dummy_input,\n",
    "                  \"./bert.onnx\",\n",
    "                  verbose=False,\n",
    "                  input_names=input_names,\n",
    "                  output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b5dbe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to('.', x, y.last_hidden_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "fca996da59dbb3c6fdf51f411e855733054c0b4b8857c96311698dd9fcd1dd43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
